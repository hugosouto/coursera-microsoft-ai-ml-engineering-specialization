{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Web scraping is a powerful method for acquiring data from websites, especially when the information you need isn’t readily available in a structured format. By setting up a web scraper in your local environment, you can automate the process of gathering large amounts of data from the web. \n",
    "\n",
    "By the end of this reading, you will be able to: \n",
    "\n",
    "Set up a basic data scraper using Python, including code snippets and explanations to help you get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before diving into the code, ensure you have the following tools installed on your local environment:\n",
    "\n",
    "- Python 3.x: Python is the language we’ll use to build our web scraper.\n",
    "\n",
    "- pip: pip is Python’s package installer, which you’ll use to install the necessary libraries.\n",
    "\n",
    "- A code editor: Examples include Jupyter Notebooks, VS Code, PyCharm, or even a simple text editor such as Sublime Text.\n",
    "\n",
    "You’ll also need a basic understanding of HTML, as web scraping involves interacting with the HTML structure of a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Microsoft Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries\n",
    "\n",
    "Start by importing the libraries you’ll need, if they’re not already in your kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Send an HTTP request to the website\n",
    "\n",
    "Use the requests library to send an HTTP GET request to the website you want to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.automl?view=azure-python'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print('Request successful!')\n",
    "else:\n",
    "    print('Failed to retrieve the webpage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Parse the HTML content\n",
    "\n",
    "Once you’ve successfully retrieved the web page, use BeautifulSoup to parse the HTML content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure.ai.ml.automl package | Microsoft Learn\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Print the title of the webpage to verify\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract the data you need\n",
    "\n",
    "Now that you have the HTML parsed, you can start extracting the data you’re interested in. Let’s say you want to scrape a list of items from a table on the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fbbd1e47-70cd-4c6b-a9b9-1f64594174fc",
       "rows": [
        [
         "0",
         null,
         null
        ],
        [
         "1",
         "training_data",
         "Input\n\n\nThe training data to be used within the experiment.\nIt should contain both training features and a label column (optionally a sample weights column)."
        ],
        [
         "2",
         "target_column_name",
         "str\n\n\nThe name of the label column.\nThis parameter is applicable to training_data, validation_data and test_data parameters"
        ],
        [
         "3",
         "primary_metric",
         "The metric that Automated Machine Learning will optimize for model selection.\nAutomated Machine Learning collects more metrics than it can optimize.\nFor more information on how metrics are calculated, see\nhttps://learn.microsoft.com/azure/machine-learning/how-to-configure-auto-train#primary-metric.\nAcceptable values: accuracy, AUC_weighted, norm_macro_recall, average_precision_score_weighted,\nand precision_score_weighted\nDefaults to accuracy"
        ],
        [
         "4",
         "enable_model_explainability",
         "bool\n\n\nWhether to enable explaining the best AutoML model at the end of all AutoML\ntraining iterations.\nThe default is None. For more information, see\nInterpretability: model explanations in automated machine learning."
        ],
        [
         "5",
         "weight_column_name",
         "str\n\n\nThe name of the sample weight column. Automated ML supports a weighted column\nas an input, causing rows in the data to be weighted up or down.\nIf the input data is from a pandas.DataFrame which doesn't have column names,\ncolumn indices can be used instead, expressed as integers.\nThis parameter is applicable to training_data and validation_data parameters"
        ],
        [
         "6",
         "validation_data",
         "Input\n\n\nThe validation data to be used within the experiment.\nIt should contain both training features and label column (optionally a sample weights column).\nDefaults to None"
        ],
        [
         "7",
         "validation_data_size",
         "float\n\n\nWhat fraction of the data to hold out for validation when user validation data\nis not specified. This should be between 0.0 and 1.0 non-inclusive.\nSpecify validation_data to provide validation data, otherwise set n_cross_validations or\nvalidation_data_size to extract validation data out of the specified training data.\nFor custom cross validation fold, use cv_split_column_names.\nFor more information, see\nConfigure data splits and cross-validation in automated machine learning.\nDefaults to None"
        ],
        [
         "8",
         "n_cross_validations",
         "Union[str, int]\n\t\t\n\nHow many cross validations to perform when user validation data is not specified.\nSpecify validation_data to provide validation data, otherwise set n_cross_validations or\nvalidation_data_size to extract validation data out of the specified training data.\nFor custom cross validation fold, use cv_split_column_names.\nFor more information, see\nConfigure data splits and cross-validation in automated machine learning.\nDefaults to None"
        ],
        [
         "9",
         "cv_split_column_names",
         "List[str]\n\t\t\n\nList of names of the columns that contain custom cross validation split.\nEach of the CV split columns represents one CV split where each row are either marked\n1 for training or 0 for validation.\nDefaults to None"
        ],
        [
         "10",
         "test_data",
         "Input\n\n\nThe Model Test feature using test datasets or test data splits is a feature in\nPreview state and might change at any time.\nThe test data to be used for a test run that will automatically be started after\nmodel training is complete. The test run will get predictions using the best model\nand will compute metrics given these predictions.\nIf this parameter or the test_data_size parameter are not specified then\nno test run will be executed automatically after model training is completed.\nTest data should contain both features and label column.\nIf test_data is specified then the target_column_name parameter must be specified.\nDefaults to None"
        ],
        [
         "11",
         "test_data_size",
         "float\n\n\nThe Model Test feature using test datasets or test data splits is a feature in\nPreview state and might change at any time.\nWhat fraction of the training data to hold out for test data for a test run that will\nautomatically be started after model training is complete. The test run will get\npredictions using the best model and will compute metrics given these predictions.\nThis should be between 0.0 and 1.0 non-inclusive.\nIf test_data_size is specified at the same time as validation_data_size,\nthen the test data is split from training_data before the validation data is split.\nFor example, if validation_data_size=0.1, test_data_size=0.1 and the original training data has\n1000 rows, then the test data will have 100 rows, the validation data will contain 90 rows and the\ntraining data will have 810 rows.\nFor regression based tasks, random sampling is used. For classification tasks, stratified sampling\nis used. Forecasting does not currently support specifying a test dataset using a train/test split.\nIf this parameter or the test_data parameter are not specified then\nno test run will be executed automatically after model training is completed.\nDefaults to None"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_data</td>\n",
       "      <td>Input\\n\\n\\nThe training data to be used within...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_column_name</td>\n",
       "      <td>str\\n\\n\\nThe name of the label column.\\nThis p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>primary_metric</td>\n",
       "      <td>The metric that Automated Machine Learning wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enable_model_explainability</td>\n",
       "      <td>bool\\n\\n\\nWhether to enable explaining the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weight_column_name</td>\n",
       "      <td>str\\n\\n\\nThe name of the sample weight column....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>validation_data</td>\n",
       "      <td>Input\\n\\n\\nThe validation data to be used with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>validation_data_size</td>\n",
       "      <td>float\\n\\n\\nWhat fraction of the data to hold o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n_cross_validations</td>\n",
       "      <td>Union[str, int]\\n\\t\\t\\n\\nHow many cross valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cv_split_column_names</td>\n",
       "      <td>List[str]\\n\\t\\t\\n\\nList of names of the column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_data</td>\n",
       "      <td>Input\\n\\n\\nThe Model Test feature using test d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_data_size</td>\n",
       "      <td>float\\n\\n\\nThe Model Test feature using test d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name  \\\n",
       "0                          None   \n",
       "1                 training_data   \n",
       "2            target_column_name   \n",
       "3                primary_metric   \n",
       "4   enable_model_explainability   \n",
       "5            weight_column_name   \n",
       "6               validation_data   \n",
       "7          validation_data_size   \n",
       "8           n_cross_validations   \n",
       "9         cv_split_column_names   \n",
       "10                    test_data   \n",
       "11               test_data_size   \n",
       "\n",
       "                                          Description  \n",
       "0                                                None  \n",
       "1   Input\\n\\n\\nThe training data to be used within...  \n",
       "2   str\\n\\n\\nThe name of the label column.\\nThis p...  \n",
       "3   The metric that Automated Machine Learning wil...  \n",
       "4   bool\\n\\n\\nWhether to enable explaining the bes...  \n",
       "5   str\\n\\n\\nThe name of the sample weight column....  \n",
       "6   Input\\n\\n\\nThe validation data to be used with...  \n",
       "7   float\\n\\n\\nWhat fraction of the data to hold o...  \n",
       "8   Union[str, int]\\n\\t\\t\\n\\nHow many cross valida...  \n",
       "9   List[str]\\n\\t\\t\\n\\nList of names of the column...  \n",
       "10  Input\\n\\n\\nThe Model Test feature using test d...  \n",
       "11  float\\n\\n\\nThe Model Test feature using test d...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the table containing the data\n",
    "table = soup.find('table', {'title': 'python-keyword-only-parameter-table'})  # Replace 'data-table' with the actual id or class of the table\n",
    "\n",
    "# Extract table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Loop through the rows and extract data\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    data.append(cols)\n",
    "\n",
    "# Convert the data into a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data, columns=['Name', 'Description'])  # Replace with actual column names\n",
    "\n",
    "# Display the scraped data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save the scraped data\n",
    "\n",
    "Finally, you can save the scraped data to a file for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('scraped_data_microsoft_learn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Scraping information from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cloud-computing comparison - Wikipedia\n",
      "                      Provider Launched Block storage Assignable IPs  \\\n",
      "0        Google Cloud Platform     2013           Yes             No   \n",
      "1  Oracle Cloud Infrastructure     2014           Yes            Yes   \n",
      "2          Amazon Web Services     2006           Yes            Yes   \n",
      "3                    IBM Cloud     2005           Yes            Yes   \n",
      "4              Microsoft Azure     2010           Yes            Yes   \n",
      "\n",
      "  SMTP support IOPS Guaranteed minimum Security  \\\n",
      "0        No[1]                     Yes   Yes[2]   \n",
      "1          Yes                     Yes   Yes[5]   \n",
      "2   Partial[6]                     Yes   Yes[7]   \n",
      "3        No[9]                     Yes  Yes[10]   \n",
      "4      Yes[11]                     Yes  Yes[12]   \n",
      "\n",
      "                                           Locations             Notes  \n",
      "0  br, ca, cl, us, be, ch, de, es, fi, it, po, nl...  SMTP blocked.[4]  \n",
      "1  us, ca, br, de, uk, nl, ch, in, aus, jp, kr, saud                    \n",
      "2  us, ca, br, ie, de, uk, cn, sg, au, jp, kr, in...   List of bugs[8]  \n",
      "3  us, gb, fr, de, nl, in, au, hk, kr, it, jp, no...                    \n",
      "4  ca, us, br, ie, nl, de, uk, cn, au, jp, in, kr...  List of bugs[13]  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send an HTTP request to the webpage\n",
    "url = 'https://en.wikipedia.org/wiki/Cloud-computing_comparison'  \n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Print the title of the webpage to verify\n",
    "print(\"Title: \" + soup.title.text)\n",
    "\n",
    "# Find the table containing the data (selecting the first table by default)\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Extract headers from the first row (using <th> tags)\n",
    "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "# Loop through the rows and extract data (skip the first row with headers)\n",
    "data = []\n",
    "for row in rows[1:]:  # Start from the second row onwards\n",
    "    cols = row.find_all('td')\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    data.append(cols)\n",
    "\n",
    "# Convert the data into a pandas DataFrame, using the extracted headers as column names\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())  \n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('scraped_data_wikipedia.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
